{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4d42896",
   "metadata": {},
   "source": [
    "# NLP for ML & Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb65234",
   "metadata": {},
   "source": [
    "### Agenda:\n",
    "\n",
    "1) Roadmap of NLP\n",
    "2) Why NLP\n",
    "3) Tokenization, stemming ..\n",
    "4) Bag of Words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9632ba",
   "metadata": {},
   "source": [
    "#### Why NLP?\n",
    "    * NLP -> Data set (Text) -> Model -> O/P\n",
    "    * How text is processed and given to a machine so that it can under stand.\n",
    "    * Vector play a major role in it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae131084",
   "metadata": {},
   "source": [
    "#### Roadmap of NLP\n",
    "\n",
    "    Text Preprocessing -> ML use case -> Deeplearning (RNN, LSTM RNN, GRU RNN) -> Advance text preprocessing (Word embedding) -> Advance deep learning(Bidirectional LSTM, Encoders, decoders) -> Transformer -> BERT\n",
    "\n",
    "    Text Preprocessing -> How we can clean the texts, convert text into words of vectors how a machine can understand what we say.\n",
    "     > Bag of Words, TD-IDF(Term Frequency-Inverse Document Frequency), stop word\n",
    "\n",
    "     * Text Preprocessing 1 (Cleaning) -> Tokenization (^Stopwords)> Stemming > Lemmatization\n",
    "     * Text Preprocessing 2 (Convert words to vectors) -> BoW, TFIDF, Unigrams, Bigrams\n",
    "     * Text preprocessing 3  -> Word2Vec, AugWord2Vec\n",
    "\n",
    "     Note: Each text processing overcomes the issues in it previous process.\n",
    "\n",
    "#### Libs Used\n",
    "    * NLTK\n",
    "    * spacy\n",
    "    * Text Blob\n",
    "    * Tensorflow/PyTorch\n",
    "    * Hugging Face\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pynb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
